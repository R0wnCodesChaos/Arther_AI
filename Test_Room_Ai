import pvporcupine, pyaudio, struct, whisper, wave, os, tempfile, threading, pygame, time, numpy as np
import ollama
from gtts import gTTS
from pathlib import Path
from typing import Optional

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš™ï¸  CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ACCESS_KEY = os.getenv("PORCUPINE_ACCESS_KEY")
USE_CUSTOM_WAKE_WORD, WAKE_WORD_PATH, BUILT_IN_WAKE_WORD = True, "Hey-Arthur_en_windows_v3_0_0.ppn", "jarvis"
MICROPHONE_INDEX, RECORD_SECONDS, SAMPLE_RATE, CHUNK_SIZE = 1, 30, 16000, 512  # Max 30 seconds
SILENCE_THRESHOLD = 500  # Lower = more sensitive to silence
SILENCE_DURATION = 1.5  # Seconds of silence before stopping
MAX_HISTORY, TEST_MODE = 10, True
OLLAMA_MODEL = "llama3.2:3b"  # Options: llama3.2:1b, llama3.2:3b, mistral, phi3, gemma2, etc.
USER_INFO = """Name: Ronan
Age: 13
Location: Noels Pond, Newfoundland, Canada
Personality:
Smart-ass, adventurous, sarcastic, and funny. Dark sense of humor, usually jokes around and doesn't take things too seriously. Likes when Arthur talks like a friend â€” casual, witty, and not robotic.
Interests:
Loves gaming (Grounded 2, Roblox, Trailmakers) and tech. Excited for Subnautica 2 and the next Grounded update. Watches mostly gaming and tech content on YouTube.
Media & Fandoms:
Favorite shows are Stranger Things and Dark ("that cool German show"). Doesn't really have a favorite character but enjoys mysterious or sci-fi vibes.
School & Learning:
Enjoys gym, math, tech, and ELA. Tolerates social studies, French, and religion. Thinks health class is boring.
Sports & Activities:
Does Taekwondo during the school season, swims all year, and goes skiing in the winter when there's snow.
Setup:
Ryzen 5 5600X (6 core), 16GB RAM, 970 EVO Plus 1TB SSD, RX 6600 GPU, dual monitors, mouse, keyboard, and a Soomfon stream controller.
Pets:
â€¢ Sophie â€” 3 years old (Oct 2025), cute but energetic and not quite trained.
â€¢ Shadow â€” 3 months old (Oct 2025), mischievous but well-trained for a pup.
â€¢ Kenzy â€” 11 years old (Oct 2025), lazy and loves belly rubs.
â€¢ Boots â€” friendly cat, not shy.
â€¢ Bianca â€” shy cat, keeps to herself.
Friends & Family:
Has two close friends (Alex and Matheo, both male). Two siblings (Isaac â€” brother, Freya â€” sister). Calls parents simply Mom and Dad."""
CUSTOM_RESPONSES = {"brother iq": "Your brother's IQ is lower than a rock. Just kidding!", "brothers iq": "Your brother's IQ is lower than a rock. Just kidding!"}
AI_NAME, AI_MAX_TOKENS, AI_TEMPERATURE = "Arthur", 200, 0.8

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ INITIALIZATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
pygame.mixer.init()
conversation_history, wake_word_queue, interrupt_event, is_speaking = [], [], threading.Event(), False
history_lock, stream_lock = threading.Lock(), threading.Lock()

# Test Ollama connection
try:
    ollama.list()
    print(f"âœ… Ollama connected | Model: {OLLAMA_MODEL}")
except Exception as e:
    print(f"âš ï¸ Ollama not running! Start it with: ollama serve")
    print(f"   Then run: ollama pull {OLLAMA_MODEL}")
    exit(1)

porcupine = pvporcupine.create(access_key=ACCESS_KEY, keyword_paths=[WAKE_WORD_PATH] if USE_CUSTOM_WAKE_WORD else None, keywords=None if USE_CUSTOM_WAKE_WORD else [BUILT_IN_WAKE_WORD])
whisper_model = whisper.load_model("base")
pa = pyaudio.PyAudio()
stream = pa.open(rate=porcupine.sample_rate, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=porcupine.frame_length, input_device_index=MICROPHONE_INDEX)

print(f"âœ… {AI_NAME} initialized | Mic: {pa.get_device_info_by_index(MICROPHONE_INDEX)['name'] if MICROPHONE_INDEX else 'default'}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”Š CORE FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def background_wake_monitor():
    global is_speaking
    while True:
        try:
            with stream_lock:
                pcm = stream.read(porcupine.frame_length, exception_on_overflow=False)
            if porcupine.process(struct.unpack_from("h" * porcupine.frame_length, pcm)) >= 0:
                (interrupt_event.set() if is_speaking else wake_word_queue.append(time.time()))
                TEST_MODE and print(f"\n{'âš ï¸ INTERRUPT!' if is_speaking else 'ğŸŸ¢ Wake word detected!'}")
        except Exception as e:
            TEST_MODE and print(f"âš ï¸ Monitor error: {e}")
            time.sleep(0.1)

def record_audio(seconds: int = RECORD_SECONDS) -> Optional[str]:
    TEST_MODE and print(f"ğŸ§ Listening... (speak now, I'll stop when you're done)")
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
        output_file = tmp_file.name
    try:
        stream2 = pa.open(format=pyaudio.paInt16, channels=1, rate=SAMPLE_RATE, input=True, frames_per_buffer=CHUNK_SIZE, input_device_index=MICROPHONE_INDEX)
        [stream2.read(CHUNK_SIZE, exception_on_overflow=False) for _ in range(5)]
        time.sleep(0.2)
        TEST_MODE and print("   ğŸ¤ Recording now! (speak naturally)")
        frames, silence_chunks = [], 0
        max_silence = int(SILENCE_DURATION * SAMPLE_RATE / CHUNK_SIZE)
        started_speaking = False
        
        for _ in range(int(SAMPLE_RATE / CHUNK_SIZE * seconds)):
            data = stream2.read(CHUNK_SIZE, exception_on_overflow=False)
            frames.append(data)
            
            # Calculate volume
            rms = np.sqrt(np.mean(np.square(np.frombuffer(data, dtype=np.int16).astype(np.float64))))
            
            # Detect if user started speaking
            if not started_speaking and rms > SILENCE_THRESHOLD:
                started_speaking = True
                TEST_MODE and print("   ğŸ—£ï¸ Speech detected!")
            
            # Only check for silence after user started speaking
            if started_speaking:
                if rms < SILENCE_THRESHOLD:
                    silence_chunks += 1
                    if silence_chunks > max_silence:
                        TEST_MODE and print("   â¹ï¸ Silence detected, stopping")
                        break
                else:
                    silence_chunks = 0
        
        stream2.stop_stream()
        stream2.close()
        if frames and len(frames) >= 3:
            with wave.open(output_file, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(pa.get_sample_size(pyaudio.paInt16))
                wf.setframerate(SAMPLE_RATE)
                wf.writeframes(b"".join(frames))
            if os.path.getsize(output_file) > 1000:
                TEST_MODE and print(f"âœ… Audio captured: {len(frames)} frames")
                return output_file
    except Exception as e:
        print(f"âŒ Recording error: {e}")
    return None

def transcribe_audio(file_path: str) -> Optional[str]:
    if not file_path or not Path(file_path).exists():
        return None
    try:
        TEST_MODE and print("ğŸ”„ Transcribing audio...")
        result = whisper_model.transcribe(file_path, language="en", fp16=False, temperature=0.0, condition_on_previous_text=False)
        transcription = result["text"].strip().replace("[BLANK_AUDIO]", "").strip()
        TEST_MODE and transcription and print(f"   ğŸ“ Transcribed: '{transcription}'")
        return transcription if len(transcription) > 2 else None
    except Exception as e:
        print(f"âŒ Transcription error: {e}")
        return None

def ask_ai(prompt: str) -> str:
    global conversation_history
    prompt_clean = prompt.lower().replace('.', '').replace(',', '')
    if "activate test mode" in prompt_clean or "enable test mode" in prompt_clean:
        globals()['TEST_MODE'] = True
        return "Test mode activated."
    elif "deactivate test mode" in prompt_clean or "disable test mode" in prompt_clean:
        globals()['TEST_MODE'] = False
        return "Test mode deactivated."
    for trigger, response in CUSTOM_RESPONSES.items():
        if trigger in prompt_clean:
            return response
    try:
        TEST_MODE and print("ğŸ¤” Thinking...")
        messages = [{"role": "system", "content": f"""You are {AI_NAME}, a friendly and conversational AI assistant. Answer questions directly and accurately.

Personality: Warm, funny, helpful, personable. Use casual language, contractions, wit, and occasional gen z slang. Keep responses 2-3 sentences unless asked for more. Be natural and engaging like a smart friend.

User Info:
{USER_INFO}

Important: Always answer the user's actual question first, then add personality. Respond in English or German if they speak German."""}]
        with history_lock:
            for entry in conversation_history[-MAX_HISTORY:]:
                messages.extend([{"role": "user", "content": entry["user"]}, {"role": "assistant", "content": entry["assistant"]}])
        messages.append({"role": "user", "content": prompt})
        
        # Use Ollama instead of OpenAI
        response = ollama.chat(
            model=OLLAMA_MODEL,
            messages=messages,
            options={
                "temperature": AI_TEMPERATURE,
                "num_predict": AI_MAX_TOKENS,
            }
        )
        
        response_text = response['message']['content'].strip()
        
        with history_lock:
            conversation_history.append({"user": prompt, "assistant": response_text})
            conversation_history = conversation_history[-MAX_HISTORY:] if len(conversation_history) > MAX_HISTORY else conversation_history
        return response_text
    except Exception as e:
        print(f"âŒ AI error: {e}")
        return "Hmm, something went wrong. Is Ollama running?"

def play_audio(file_path: str) -> bool:
    try:
        pygame.mixer.music.load(file_path)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            if interrupt_event.is_set():
                pygame.mixer.music.stop()
                pygame.mixer.music.unload()
                return False
            pygame.time.Clock().tick(100)
        pygame.mixer.music.unload()
        return True
    except:
        return False

def speak(text: str) -> bool:
    global is_speaking
    print(f"{'ğŸ’¬ ' if TEST_MODE else ''}{AI_NAME}: {text}")
    interrupt_event.clear()
    is_speaking = True
    try:
        if interrupt_event.is_set():
            return False
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp:
            audio_file = tmp.name
        gTTS(text=text, lang='en', slow=False).save(audio_file)
        success = play_audio(audio_file)
        try:
            time.sleep(0.1)
            os.remove(audio_file)
        except:
            pass
        return success
    except Exception as e:
        print(f"âŒ TTS failed: {e}")
        return False
    finally:
        is_speaking = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ MAIN LOOP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
threading.Thread(target=background_wake_monitor, daemon=True).start()
wake_phrase = "Hey Arthur" if USE_CUSTOM_WAKE_WORD else BUILT_IN_WAKE_WORD.title()
print(f"ğŸ™ï¸ {AI_NAME} is ready. Say '{wake_phrase}' to begin.\n")

try:
    while True:
        if wake_word_queue:
            wake_word_queue.clear()
            if is_speaking:
                interrupt_event.set()
                pygame.mixer.music.stop()
                is_speaking = False
                time.sleep(0.3)
            interrupt_event.clear()
            audio_file = record_audio()
            if audio_file:
                command = transcribe_audio(audio_file)
                if command and len(command.strip()) > 2:
                    print(f"{'ğŸ—£ï¸ ' if TEST_MODE else ''}You: {command}")
                    speak(ask_ai(command))
                    os.remove(audio_file)
                else:
                    TEST_MODE and print("âš ï¸ Could not understand speech")
                    speak("I didn't catch that. Could you speak louder?")
            else:
                speak("I had trouble recording. Please try again.")
            TEST_MODE and print(f"\nğŸ™ï¸ Ready for next command... (Memory: {len(conversation_history)} exchanges)")
        time.sleep(0.05)
except KeyboardInterrupt:
    print("\n\nğŸ›‘ Shutting down...")
finally:
    stream.stop_stream()
    stream.close()
    pa.terminate()
    porcupine.delete()
    pygame.mixer.quit()
    print("ğŸ‘‹ Goodbye!")